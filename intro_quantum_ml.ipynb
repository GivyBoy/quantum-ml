{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Intro to Quantum ML\n",
    "\n",
    "- The idea is to explore the potential applications of quantum computing in machine learning\n",
    "\n",
    "### Model\n",
    "\n",
    "- We'll be looking at using a QCNN (Quantum CNN) for classifying MNIST images. This is a fairly simple dataset, which makes it perfect for to test the efficacy of the Quantum Algorithm. In order to compare the model's performance, we will compare it to [LeNet-5](\"http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf\"). This model was released in 1998 by Yann LeCun. It was one of the earliest convnets used for image recognition, so it seems reasonable to consider it as a baseline for comparison to the QCNN, which is still in its infancy. `[we can't do this comparison yet]`\n",
    "\n",
    "- Additionally, we will comapre both a Quantum and Classical Autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim  # used for optimization libraries (SGD, Adam, etc)\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  # used for progress bars\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(17)  # computers a (pseudo) random, so specifying a seed allows for reproducibility\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Steps (for classical models)\n",
    "\n",
    "- Define hyperparams and util functions\n",
    "- Create models\n",
    "- Create dataloaders\n",
    "- Train models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "learning_rate = 1e-3\n",
    "nb_channels = 16\n",
    "embedding_dim = 8\n",
    "batch_size = 64\n",
    "nb_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def plot_imgs(input, output):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow(input, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Input\")\n",
    "    ax[1].imshow(output, cmap=\"gray\")\n",
    "    ax[1].set_title(\"Output\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_autoencoder(model, train_loader, optimizer, nb_epochs):\n",
    "    for epoch in range(nb_epochs):\n",
    "        acc_loss = 0\n",
    "        for batch_idx, data in enumerate(tqdm(train_loader)):\n",
    "            # send the data to cuda, if possible\n",
    "            data = data.to(DEVICE)\n",
    "            output = model(data)\n",
    "            loss = 0.5 * (output - data).pow(2).sum() / data.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {acc_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=6,\n",
    "            kernel_size=(5, 5),\n",
    "            stride=(1, 1),\n",
    "            padding=(0, 0),\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=6,\n",
    "            out_channels=16,\n",
    "            kernel_size=(5, 5),\n",
    "            stride=(1, 1),\n",
    "            padding=(0, 0),\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=16,\n",
    "            out_channels=120,\n",
    "            kernel_size=(5, 5),\n",
    "            stride=(1, 1),\n",
    "            padding=(0, 0),\n",
    "        )\n",
    "        self.linear1 = nn.Linear(120, 84)\n",
    "        self.linear2 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to reduce the size of the image, so instead of cropping we can use an autoencoder ro reduce the dimensionality\n",
    "# note: PCA is a linear autoencoder\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, nb_channels: int, embedding_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, nb_channels, kernel_size=5),  # to 24x24 - we are using MNIST\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(nb_channels, nb_channels, kernel_size=5),  # to 20x20\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(nb_channels, nb_channels, kernel_size=4, stride=2),  # to 9x9\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(nb_channels, nb_channels, kernel_size=3, stride=2),  # to 4x4\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(nb_channels, embedding_dim, kernel_size=4),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(embedding_dim, nb_channels, kernel_size=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(nb_channels, nb_channels, kernel_size=3, stride=2),  # from 4x4\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(nb_channels, nb_channels, kernel_size=4, stride=2),  # from 9x9\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(nb_channels, nb_channels, kernel_size=5),  # from 20x20\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(nb_channels, 1, kernel_size=5),  # from 24x24\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x).view(x.size(0), -1)\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z.view(z.size(0), -1, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_train_set = datasets.MNIST(\"data/mnist/\", train=True, download=True)\n",
    "ae_train_dataset = ae_train_set.data.view(-1, 1, 28, 28).float()\n",
    "mu, std = ae_train_dataset.mean(), ae_train_dataset.std()\n",
    "ae_train_dataset.sub_(mu).div_(std)\n",
    "ae_train_loader = DataLoader(dataset=ae_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "ae_test_set = datasets.MNIST(\"data/mnist/\", train=False, download=True)\n",
    "ae_test_dataset = ae_test_set.data.view(-1, 1, 28, 28).float()\n",
    "ae_test_dataset.sub_(mu).div_(std)\n",
    "None  # we don't need the test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "autoencoder = AutoEncoder(nb_channels=nb_channels, embedding_dim=embedding_dim)\n",
    "autoencoder = autoencoder.to(device)\n",
    "\n",
    "ae_optimizer = optim.AdamW(autoencoder.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_autoencoder(autoencoder, ae_train_loader, ae_optimizer, nb_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = ae_test_dataset[56].to(device)\n",
    "\n",
    "# Encode / decode\n",
    "z = autoencoder.encode(input)\n",
    "output = autoencoder.decode(z)\n",
    "\n",
    "plot_imgs(input.cpu().detach().numpy().squeeze(), output.cpu().detach().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.circuit.library import ZFeatureMap\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "algorithm_globals.random_seed = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_circuit(params):\n",
    "    target = QuantumCircuit(2)\n",
    "    target.rz(-np.pi / 2, 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(params[0], 0)\n",
    "    target.ry(params[1], 1)\n",
    "    target.cx(0, 1)\n",
    "    target.ry(params[2], 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(np.pi / 2, 0)\n",
    "    return target\n",
    "\n",
    "\n",
    "# Let's draw this circuit and see what it looks like\n",
    "params = ParameterVector(\"θ\", length=3)\n",
    "circuit = conv_circuit(params)\n",
    "circuit.draw(\"mpl\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(num_qubits, param_prefix):\n",
    "    qc = QuantumCircuit(num_qubits, name=\"Convolutional Layer\")\n",
    "    qubits = list(range(num_qubits))\n",
    "    param_index = 0\n",
    "    params = ParameterVector(param_prefix, length=num_qubits * 3)\n",
    "    for q1, q2 in zip(qubits[0::2], qubits[1::2]):\n",
    "        qc = qc.compose(conv_circuit(params[param_index : (param_index + 3)]), [q1, q2])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "    for q1, q2 in zip(qubits[1::2], qubits[2::2] + [0]):\n",
    "        qc = qc.compose(conv_circuit(params[param_index : (param_index + 3)]), [q1, q2])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "\n",
    "    qc_inst = qc.to_instruction()\n",
    "\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    qc.append(qc_inst, qubits)\n",
    "    return qc\n",
    "\n",
    "\n",
    "circuit = conv_layer(4, \"θ\")\n",
    "circuit.decompose().draw(\"mpl\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_circuit(params):\n",
    "    target = QuantumCircuit(2)\n",
    "    target.rz(-np.pi / 2, 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(params[0], 0)\n",
    "    target.ry(params[1], 1)\n",
    "    target.cx(0, 1)\n",
    "    target.ry(params[2], 1)\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "params = ParameterVector(\"θ\", length=3)\n",
    "circuit = pool_circuit(params)\n",
    "circuit.draw(\"mpl\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_layer(sources, sinks, param_prefix):\n",
    "    num_qubits = len(sources) + len(sinks)\n",
    "    qc = QuantumCircuit(num_qubits, name=\"Pooling Layer\")\n",
    "    param_index = 0\n",
    "    params = ParameterVector(param_prefix, length=num_qubits // 2 * 3)\n",
    "    for source, sink in zip(sources, sinks):\n",
    "        qc = qc.compose(pool_circuit(params[param_index : (param_index + 3)]), [source, sink])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "\n",
    "    qc_inst = qc.to_instruction()\n",
    "\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    qc.append(qc_inst, range(num_qubits))\n",
    "    return qc\n",
    "\n",
    "\n",
    "sources = [0, 1]\n",
    "sinks = [2, 3]\n",
    "circuit = pool_layer(sources, sinks, \"θ\")\n",
    "circuit.decompose().draw(\"mpl\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes too long to train QCNN\n",
    "\n",
    "# qcnn_train_set = datasets.MNIST(\"data/mnist/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "# qcnn_test_set = datasets.MNIST(\"data/mnist/\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = (\n",
    "#     qcnn_train_set.data,\n",
    "#     qcnn_test_set.data,\n",
    "#     qcnn_train_set.targets,\n",
    "#     qcnn_test_set.targets,\n",
    "# )\n",
    "\n",
    "# X_train = X_train.unsqueeze(1).reshape(-1, 1, 28, 28).to(torch.float32)\n",
    "# X_test = X_test.unsqueeze(1).reshape(-1, 1, 28, 28).to(torch.float32)\n",
    "\n",
    "# X_train_encoded = autoencoder.encode(X_train.to(device)).detach().cpu().numpy()\n",
    "# X_test_encoded = autoencoder.encode(X_test.to(device)).detach().cpu().numpy()\n",
    "# y_train = y_train.numpy()\n",
    "# y_test = y_test.numpy()\n",
    "\n",
    "# X_train_encoded = np.concatenate(\n",
    "#     (X_train_encoded[np.where(y_train == 3)[0]], X_train_encoded[np.where(y_train == 6)[0]])\n",
    "# )\n",
    "# y_train = np.concatenate((y_train[np.where(y_train == 3)[0]], y_train[np.where(y_train == 6)[0]]))\n",
    "\n",
    "# X_test_encoded = np.concatenate((X_test_encoded[np.where(y_test == 3)[0]], X_test_encoded[np.where(y_test == 6)[0]]))\n",
    "# y_test = np.concatenate((y_test[np.where(y_test == 3)[0]], y_test[np.where(y_test == 6)[0]]))\n",
    "\n",
    "# X_train_encoded, y_train = shuffle(X_train_encoded, y_train, random_state=17)\n",
    "# X_test_encoded, y_test = shuffle(X_test_encoded, y_test, random_state=17)\n",
    "\n",
    "# # labels/targets need to be 1 and -1\n",
    "# y_train[y_train == 3] = -1\n",
    "# y_train[y_train == 6] = 1\n",
    "# y_test[y_test == 3] = -1\n",
    "# y_test[y_test == 6] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(num_images):\n",
    "    images = []\n",
    "    labels = []\n",
    "    hor_array = np.zeros((6, 8))\n",
    "    ver_array = np.zeros((4, 8))\n",
    "\n",
    "    j = 0\n",
    "    for i in range(0, 7):\n",
    "        if i != 3:\n",
    "            hor_array[j][i] = np.pi / 2\n",
    "            hor_array[j][i + 1] = np.pi / 2\n",
    "            j += 1\n",
    "\n",
    "    j = 0\n",
    "    for i in range(0, 4):\n",
    "        ver_array[j][i] = np.pi / 2\n",
    "        ver_array[j][i + 4] = np.pi / 2\n",
    "        j += 1\n",
    "\n",
    "    for n in range(num_images):\n",
    "        rng = algorithm_globals.random.integers(0, 2)\n",
    "        if rng == 0:\n",
    "            labels.append(-1)\n",
    "            random_image = algorithm_globals.random.integers(0, 6)\n",
    "            images.append(np.array(hor_array[random_image]))\n",
    "        elif rng == 1:\n",
    "            labels.append(1)\n",
    "            random_image = algorithm_globals.random.integers(0, 4)\n",
    "            images.append(np.array(ver_array[random_image]))\n",
    "\n",
    "        # Create noise\n",
    "        for i in range(8):\n",
    "            if images[-1][i] == 0:\n",
    "                images[-1][i] = algorithm_globals.random.uniform(0, np.pi / 4)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = generate_dataset(100)\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.3, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = ZFeatureMap(8)\n",
    "\n",
    "ansatz = QuantumCircuit(8, name=\"Ansatz\")\n",
    "\n",
    "# First Convolutional Layer\n",
    "ansatz.compose(conv_layer(8, \"c1\"), list(range(8)), inplace=True)\n",
    "\n",
    "# First Pooling Layer\n",
    "ansatz.compose(pool_layer([0, 1, 2, 3], [4, 5, 6, 7], \"p1\"), list(range(8)), inplace=True)\n",
    "\n",
    "# Second Convolutional Layer\n",
    "ansatz.compose(conv_layer(4, \"c2\"), list(range(4, 8)), inplace=True)\n",
    "\n",
    "# Second Pooling Layer\n",
    "ansatz.compose(pool_layer([0, 1], [2, 3], \"p2\"), list(range(4, 8)), inplace=True)\n",
    "\n",
    "# Third Convolutional Layer\n",
    "ansatz.compose(conv_layer(2, \"c3\"), list(range(6, 8)), inplace=True)\n",
    "\n",
    "# Third Pooling Layer\n",
    "ansatz.compose(pool_layer([0], [1], \"p3\"), list(range(6, 8)), inplace=True)\n",
    "\n",
    "# Combining the feature map and ansatz\n",
    "circuit = QuantumCircuit(8)\n",
    "circuit.compose(feature_map, range(8), inplace=True)\n",
    "circuit.compose(ansatz, range(8), inplace=True)\n",
    "\n",
    "observable = SparsePauliOp.from_list([(\"Z\" + \"I\" * 7, 1)])\n",
    "\n",
    "# we decompose the circuit for the QNN to avoid additional data copying\n",
    "qnn = EstimatorQNN(\n",
    "    circuit=circuit.decompose(),\n",
    "    observables=observable,\n",
    "    input_params=feature_map.parameters,\n",
    "    weight_params=ansatz.parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit.draw(\"mpl\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_graph(weights, obj_func_eval):\n",
    "    clear_output(wait=True)\n",
    "    objective_func_vals.append(obj_func_eval)\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NeuralNetworkClassifier(\n",
    "    qnn,\n",
    "    optimizer=COBYLA(maxiter=200),  # Set max iterations here\n",
    "    callback=callback_graph,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_func_vals = []\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "# classifier.fit(X_train_encoded, y_train)\n",
    "\n",
    "x = np.asarray(train_images)\n",
    "y = np.asarray(train_labels)\n",
    "classifier.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(test_images)\n",
    "y = np.asarray(test_labels)\n",
    "print(f\"Accuracy from the test data : {np.round(100 * classifier.score(x, y), 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Autoencoder\n",
    "\n",
    "- to-do\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
